{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 from tensorflow to HLS4ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/\")  # just to enable `dataset`\n",
    "sys.path.append(\n",
    "    \"/home/webphy/Desktop/dnn_processor/dataset/\"\n",
    ")  # just to enable `dataset`\n",
    "\n",
    "import dataset\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64\n",
    "train_images_rgx = \"../dataset/resized_dataset_texturas_v2/*/*.jpeg\"\n",
    "valid_images_rgx = \"../dataset/resized_dataset_texturas_v2_test/*/*.jpeg\"\n",
    "\n",
    "train_ds, val_ds, nclasses = dataset.create_datasets(\n",
    "    train_images_rgx, valid_images_rgx, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "model_trial_id = 271\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    f\"../neural_network/automl/saved_models/striped_models/exp6_aug_calib/{model_trial_id}.h5\"\n",
    ")\n",
    "\n",
    "# x = x_in = keras.layers.Input(shape=(256,256,3))\n",
    "# for l in model.layers[1:]:\n",
    "#     x = l(x)\n",
    "#\n",
    "#     if l.name == \"activation_956\":\n",
    "#         break\n",
    "# new_model = keras.models.Model(x_in, x)\n",
    "# new_model.summary()\n",
    "\n",
    "model.layers[-1].activation = keras.activations.linear\n",
    "model.compile(\n",
    "    \"adam\",\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# model.summary()\n",
    "new_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(val_ds)\n",
    "print(\"Accuracy: {}\".format(score[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to FPGA firmware with hls4ml\n",
    "\n",
    "### Make an hls4ml config & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    new_model,\n",
    "    granularity=\"name\",\n",
    "    default_precision=\"fixed<4,4>\",\n",
    "    default_reuse_factor=2048,\n",
    "    \n",
    ")\n",
    "\n",
    "config[\"Model\"][\"Strategy\"] = \"Resource\"\n",
    "\n",
    "for layer in config[\"LayerName\"].keys():\n",
    "    config[\"LayerName\"][layer][\"Strategy\"] = \"Resource\"\n",
    "\n",
    "config[\"LayerName\"][\"depthwise_conv2d_220\"][\"Strategy\"] = \"Latency\"\n",
    "config[\"LayerName\"][\"depthwise_conv2d_221\"][\"Strategy\"] = \"Latency\"\n",
    "\n",
    "config[\"LayerName\"][f\"dense_{model_trial_id}\"][\"ReuseFactor\"] = 4000\n",
    "config[\"LayerName\"][f\"dense_{model_trial_id}\"][\"Strategy\"] = \"Resource\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    new_model,\n",
    "    hls_config=config,\n",
    "    output_dir=f\"model_{model_trial_id}/hls4ml_prj\",\n",
    "    part=\"xc7z020-clg400-1\",\n",
    "    io_type=\"io_stream\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise what we created. The model architecture is shown, annotated with the shape and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, predict\n",
    "\n",
    "Now we need to check that this model performance is still good. We compile the hls_model, and then use `hls_model.predict` to execute the FPGA firmware with bit-accurate emulation on the CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset__ = list(val_ds.as_numpy_iterator())\n",
    "val_x = dataset__[0][0]\n",
    "val_y = dataset__[0][1]\n",
    "\n",
    "hls_model.compile()\n",
    "val_ds_np = np.ascontiguousarray(val_x).astype(np.float32)\n",
    "y_hls = hls_model.predict(val_ds_np)\n",
    "y_hls = tf.nn.softmax(y_hls).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "\n",
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "y_keras = new_model.predict(val_x)\n",
    "y_keras = tf.nn.softmax(y_keras, axis=-1).numpy()\n",
    "\n",
    "print(\n",
    "    \"Keras  Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(val_y, axis=-1), np.argmax(y_keras, axis=-1))\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"hls4ml Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(val_y, axis=1), np.argmax(y_hls, axis=1))\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(val_y, y_keras, classes)\n",
    "plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "_ = plotting.makeRoc(val_y, y_hls, classes, linestyle=\"--\")\n",
    "\n",
    "lines = [Line2D([0], [0], ls=\"-\"), Line2D([0], [0], ls=\"--\")]\n",
    "\n",
    "leg = Legend(ax, lines, labels=[\"keras\", \"hls4ml\"], loc=\"lower right\", frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize\n",
    "\n",
    "**This can take several minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the reports\n",
    "\n",
    "Print out the reports generated by Vivado HLS. Pay attention to the Latency and the 'Utilization Estimates' sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report(f\"model_{model_trial_id}/hls4ml_prj/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
