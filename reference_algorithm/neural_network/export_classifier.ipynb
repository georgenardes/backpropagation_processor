{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model = tf.keras.models.load_model(\n",
    "    r\"./saved_models/encoder_v3\",\n",
    "    custom_objects={\"custom_loss\": None},\n",
    ")\n",
    "\n",
    "autoencoder_model.trainable = False\n",
    "model_input = autoencoder_model.layers[0].input\n",
    "encoder_output = autoencoder_model.get_layer(\"encoder_output\").output\n",
    "encoder = keras.Model(inputs=[model_input], outputs=[encoder_output])\n",
    "\n",
    "x = x_in = keras.layers.Input((256, 256, 3))\n",
    "\n",
    "encoder_output = encoder(x)\n",
    "\n",
    "\"\"\"\n",
    "x = keras.layers.Conv2D(\n",
    "    8,\n",
    "    kernel_size=3,\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    ")(encoder_output)\n",
    "\"\"\"\n",
    "\n",
    "x = keras.layers.Flatten()(encoder_output)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(5, \"softmax\")(x)\n",
    "\n",
    "# create model\n",
    "classifier = keras.Model(inputs=[x_in], outputs=[x])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.load_model(r\"./saved_models/classifier_v2\")\n",
    "classifier.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers:\n",
    "            print(l2)\n",
    "\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights as numpy file\n",
    "\n",
    "the name of the file indicates the 'type' of the layer, the layer 'name', and 'activation', separeted by '.'.\\\n",
    "eg: Conv2D.encoder_output.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_layer_file(id, layer, path):\n",
    "    layer_name = layer.name\n",
    "    layer_type = None\n",
    "    activation_type = \"Linear\"\n",
    "    weights, bias = [[], []]\n",
    "    \n",
    "    layer_config = layer.get_config()\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_type = \"Conv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer_config[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer_type = \"DepthwiseConv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_type = \"Dense\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "        layer_type = \"Flatten\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        layer_type = \"InputLayer\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dropout):\n",
    "        layer_type = \"Dropout\"\n",
    "\n",
    "    else:\n",
    "        print(f\"layer type {type(layer)} not expected..\")\n",
    "\n",
    "    weight_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.weights.npy\"\n",
    "    bias_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.bias.npy\"\n",
    "\n",
    "    np.save(\n",
    "        f\"{path}/\" + weight_path,\n",
    "        weights,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{path}/\" + bias_path,\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "    layerJson = {\n",
    "        \"layerName\": layer_name,\n",
    "        \"layerType\": layer_type,\n",
    "        \"activation\": activation_type,\n",
    "        \"weightPath\": weight_path,\n",
    "        \"biasPath\": bias_path,\n",
    "        \"layer_config\" : layer_config\n",
    "    }\n",
    "\n",
    "    return layerJson\n",
    "\n",
    "\n",
    "\n",
    "save_path = f\"./saved_models/classifier_v2\"\n",
    "modelJson = {\n",
    "    \"modelName\": \"classifier_v2\",\n",
    "    \"layers\": [],\n",
    "}\n",
    "\n",
    "\n",
    "index = 0\n",
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers[1:]:\n",
    "            layerJson = save_layer_file(index, l2, save_path)\n",
    "            modelJson[\"layers\"].append(layerJson)\n",
    "            index += 1\n",
    "    else:\n",
    "        print(l.name)\n",
    "        layerJson = save_layer_file(index, l, save_path)\n",
    "        modelJson[\"layers\"].append(layerJson)\n",
    "        index += 1\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"{save_path}/model.json\", \"w\") as file:\n",
    "    file.write(json.dumps(modelJson))\n",
    "    print(\"model exported ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the numpy dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Dense\n",
    "from Activations import Softmax\n",
    "\n",
    "softmax = Softmax()\n",
    "fc = Dense(\"dense\", activation=softmax)\n",
    "fc.load_weights(\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.weights.npy\",\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tensorflow layer and the numpy layer on the same input\n",
    "\n",
    "denseLayer = classifier.get_layer(\"dense\")\n",
    "\n",
    "input_test = np.ones((32, denseLayer.get_weights()[0].shape[0]))\n",
    "\n",
    "o_dut = fc(input_test, False).astype(np.float16).ravel()\n",
    "o_dur = denseLayer(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "np.savetxt(\"dut_fc.txt\", o_dut)\n",
    "np.savetxt(\"dur_fc.txt\", o_dur)\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed. Check dut_fc and dur_fc .txt files for more details.\"\n",
    "\n",
    "\n",
    "print(\"test_passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create conv2D numpy layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Conv2D\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "\n",
    "conv2D_ref = classifier.layers[1].get_layer(\"conv2d\")\n",
    "input_test = np.ones((1, 13, 13, conv2D_ref.weights[0].shape[-2]))\n",
    "\n",
    "\n",
    "npConv2D = Conv2D(\n",
    "    strides=conv2D_ref.get_config()[\"strides\"],\n",
    "    padding=conv2D_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(conv2D_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.bias.npy\",\n",
    ")\n",
    "\n",
    "\n",
    "assert np.all(conv2D_ref.weights[0] == npConv2D.weights), \"weights are different\"\n",
    "assert np.all(conv2D_ref.weights[1] == npConv2D.bias), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_dut = npConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = conv2D_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "np.savetxt(\"dut_conv.txt\", o_dut.ravel())\n",
    "np.savetxt(\"dur_conv.txt\", o_dur.ravel())\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_conv.txt and dur_conv.txt files. \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import DephtwiseConv2D\n",
    "\n",
    "depthwise_conv2d_ref = classifier.layers[1].get_layer(\"depthwise_conv2d\")\n",
    "\n",
    "npDephtwiseConv2D = DephtwiseConv2D(\n",
    "    strides=depthwise_conv2d_ref.get_config()[\"strides\"],\n",
    "    padding=depthwise_conv2d_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(depthwise_conv2d_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npDephtwiseConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.bias.npy\",\n",
    ")\n",
    "\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[0] == npDephtwiseConv2D.weights\n",
    "), \"weights are different\"\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[1] == npDephtwiseConv2D.bias\n",
    "), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = np.ones((1, 32, 32, depthwise_conv2d_ref.weights[0].shape[-2]))\n",
    "\n",
    "o_dut = npDephtwiseConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = depthwise_conv2d_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "print(o_dut)\n",
    "print(o_dur)\n",
    "\n",
    "np.savetxt(\"dut_dconv.txt\", (o_dut.ravel()*100).astype(np.int32), fmt=\"%d\")\n",
    "np.savetxt(\"dur_dconv.txt\", (o_dur.ravel()*100).astype(np.int32), fmt=\"%d\")\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_dconv.txt and dur_dconv.txt files \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from NumpyModel import Model\n",
    "from Layers import InputLayer, Conv2D, Dense, DephtwiseConv2D, Flatten\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classifier_model_path = \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/\"\n",
    "\n",
    "modelJson = json.load(open(classifier_model_path + \"model.json\"))\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "for layerConfig in modelJson[\"layers\"]:\n",
    "    if layerConfig[\"layerType\"] == \"InputLayer\":\n",
    "        layer = InputLayer(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Conv2D\":\n",
    "        layer = Conv2D(\n",
    "            padding=layerConfig[\"layer_config\"][\"padding\"],\n",
    "            strides=layerConfig[\"layer_config\"][\"strides\"],\n",
    "            name=layerConfig[\"layerName\"],\n",
    "        )\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"DepthwiseConv2D\":\n",
    "        layer = DephtwiseConv2D(\n",
    "            padding=layerConfig[\"layer_config\"][\"padding\"],\n",
    "            strides=layerConfig[\"layer_config\"][\"strides\"],\n",
    "            name=layerConfig[\"layerName\"],\n",
    "        )\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dense\":\n",
    "        layer = Dense(layerConfig[\"layerName\"])\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Flatten\":\n",
    "        layer = Flatten(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dropout\":\n",
    "        print(\"ignoring not implemented dropout\")\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(layerConfig)\n",
    "        raise NotImplementedError(layerConfig[\"layerName\"])\n",
    "\n",
    "    model.layers.append(layer)\n",
    "\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "classifier = tf.keras.models.load_model(r\"./saved_models/classifier_v2\")\n",
    "classifier.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.layers[0].get_config()[\"batch_input_shape\"])\n",
    "input_test = np.zeros(\n",
    "    shape=[\n",
    "        1,\n",
    "    ]\n",
    "    + list(classifier.layers[0].get_config()[\"batch_input_shape\"][1:])\n",
    ")\n",
    "\n",
    "\n",
    "print(classifier(input_test).numpy())\n",
    "print(model(input_test, training=False).astype(np.float16))\n",
    "\n",
    "\n",
    "o_dut_model = classifier(input_test).numpy()\n",
    "o_ref_model = model(input_test, training=False).astype(np.float16)\n",
    "\n",
    "assert np.all(o_dut_model == o_ref_model), \"val test failed. Check values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
