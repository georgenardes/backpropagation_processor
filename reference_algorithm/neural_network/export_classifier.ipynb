{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 10:22:11.836215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 10:22:12.036428: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 10:22:12.755184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-06 10:22:12.755269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-06 10:22:12.755278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 10:22:13.888461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-06 10:22:13.921639: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-01-06 10:22:13.921660: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-06 10:22:13.922857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 16, 16, 16)        6840      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,325\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 6,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model = tf.keras.models.load_model(\n",
    "    r\"./saved_models/encoder_v3\",\n",
    "    custom_objects={\"custom_loss\": None},\n",
    ")\n",
    "\n",
    "autoencoder_model.trainable = False\n",
    "model_input = autoencoder_model.layers[0].input\n",
    "encoder_output = autoencoder_model.get_layer(\"encoder_output\").output\n",
    "encoder = keras.Model(inputs=[model_input], outputs=[encoder_output])\n",
    "\n",
    "x = x_in = keras.layers.Input((256, 256, 3))\n",
    "\n",
    "encoder_output = encoder(x)\n",
    "\n",
    "\n",
    "x = keras.layers.Flatten()(encoder_output)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(5, \"softmax\")(x)\n",
    "\n",
    "# create model\n",
    "classifier = keras.Model(inputs=[x_in], outputs=[x])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " model_2 (Functional)        (None, 16, 16, 16)        6840      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_layer (InputLayer)  [(None, 256, 256, 3)]     0         |\n",
      "|                                                               |\n",
      "| depthwise_conv2d (Depthwise  (None, 16, 16, 24)     6168      |\n",
      "| Conv2D)                                                       |\n",
      "|                                                               |\n",
      "| conv2d (Conv2D)           (None, 16, 16, 16)        400       |\n",
      "|                                                               |\n",
      "| encoder_output (Conv2D)   (None, 16, 16, 16)        272       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,325\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 6,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.keras.models.load_model(r\"./saved_models/classifier_v2\")\n",
    "\n",
    "classifier.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f4bc45cb670>\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7f4bc45ca140>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4bc4647820>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4bc4645540>\n",
      "model_2\n",
      "flatten\n",
      "dropout\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers:\n",
    "            print(l2)\n",
    "\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights as numpy file\n",
    "\n",
    "the name of the file indicates the 'type' of the layer, the layer 'name', and 'activation', separeted by '.'.\\\n",
    "eg: Conv2D.encoder_output.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "flatten\n",
      "dropout\n",
      "layer type <class 'keras.layers.regularization.dropout.Dropout'> not expected..\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "def save_layer_file(id, layer):\n",
    "    layer_name = layer.name\n",
    "    layer_type = None\n",
    "    activation_type = \"Linear\"\n",
    "    weights, bias = [[], []]\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_type = \"Conv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer_type = \"DepthwiseConv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_type = \"Dense\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "        layer_type = \"Flatten\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        layer_type = \"InputLayer\"\n",
    "\n",
    "    else:\n",
    "        print(f\"layer type {type(layer)} not expected..\")\n",
    "\n",
    "\n",
    "    np.save(\n",
    "        f\"./saved_models/classifier_v2/{id}.{layer_type}.{layer_name}.{activation_type}.weights\",\n",
    "        weights,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"./saved_models/classifier_v2/{id}.{layer_type}.{layer_name}.{activation_type}.bias\",\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "\n",
    "index = 0\n",
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "\n",
    "        for l2 in l.layers[1:]:\n",
    "            save_layer_file(index, l2)\n",
    "\n",
    "            index += 1\n",
    "    else:\n",
    "        print(l.name)\n",
    "        save_layer_file(index, l)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseLayer = classifier.get_layer(name=\"dense\")\n",
    "\n",
    "weights, bias = denseLayer.get_weights()\n",
    "\n",
    "np.save(\"./saved_models/classifier_v2/dense_weights\", weights)\n",
    "np.save(\"./saved_models/classifier_v2/dense_bias\", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the numpy layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reference_algorithm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mLayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Softmax\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m softmax \u001b[39m=\u001b[39m Softmax()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fc \u001b[39m=\u001b[39m Dense(\u001b[39m\"\u001b[39m\u001b[39mdense\u001b[39m\u001b[39m\"\u001b[39m, activation\u001b[39m=\u001b[39msoftmax)\n",
      "File \u001b[0;32m~/Desktop/dnn_processor/reference_algorithm/neural_network/Layers/__init__.py:3\u001b[0m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreference_algorithm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneural_network\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mLayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDense\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mLayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSoftmax\u001b[39;00m \u001b[39mimport\u001b[39;00m Softmax\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mLayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mFlatten\u001b[39;00m \u001b[39mimport\u001b[39;00m Flatten\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'reference_algorithm'"
     ]
    }
   ],
   "source": [
    "from Layers import Dense, Softmax\n",
    "\n",
    "softmax = Softmax()\n",
    "fc = Dense(\"dense\", activation=softmax)\n",
    "fc.load_weights(\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.weights.npy\",\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the tensorflow layer and the numpy layer on the same input\n",
    "\n",
    "input_test = np.zeros((32,4096))\n",
    "\n",
    "print(fc(input_test, False))\n",
    "print(denseLayer(input_test).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
