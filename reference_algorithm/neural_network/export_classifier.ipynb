{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 15:55:13.908816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 15:55:14.080626: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-07 15:55:14.823524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-07 15:55:14.823615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-07 15:55:14.823623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 15:55:15.878650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-07 15:55:15.919646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-01-07 15:55:15.919669: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-07 15:55:15.920087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 16, 16, 16)        6840      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,325\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 6,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder_model = tf.keras.models.load_model(\n",
    "    r\"./saved_models/encoder_v3\",\n",
    "    custom_objects={\"custom_loss\": None},\n",
    ")\n",
    "\n",
    "autoencoder_model.trainable = False\n",
    "model_input = autoencoder_model.layers[0].input\n",
    "encoder_output = autoencoder_model.get_layer(\"encoder_output\").output\n",
    "encoder = keras.Model(inputs=[model_input], outputs=[encoder_output])\n",
    "\n",
    "x = x_in = keras.layers.Input((256, 256, 3))\n",
    "\n",
    "encoder_output = encoder(x)\n",
    "\n",
    "x = keras.layers.Flatten()(encoder_output)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(5, \"softmax\")(x)\n",
    "\n",
    "# create model\n",
    "classifier = keras.Model(inputs=[x_in], outputs=[x])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "loaded_classifier = tf.keras.models.load_model(r\"./saved_models/classifier_v2\")\n",
    "\n",
    "\n",
    "#classifier.summary(expand_nested=True)\n",
    "\n",
    "classifier_cfg = classifier.get_config()\n",
    "for i, layer_cfg in enumerate(classifier_cfg[\"layers\"][1][\"config\"][\"layers\"]):\n",
    "    classifier_cfg[\"layers\"][1][\"config\"][\"layers\"][i]['config']['dtype'] = 'float32'\n",
    "    print(layer_cfg['config']['dtype'])\n",
    "\n",
    "classifier = keras.Model().from_config(classifier_cfg)\n",
    "classifier.set_weights(loaded_classifier.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fcd001c7310>\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fcd001c69e0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fcd001c5e40>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fcd001c6da0>\n",
      "flatten\n",
      "dropout\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers:\n",
    "            print(l2)\n",
    "    else:\n",
    "        print(l.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights as numpy file\n",
    "\n",
    "the name of the file indicates the 'type' of the layer, the layer 'name', and 'activation', separeted by '.'.\\\n",
    "eg: Conv2D.encoder_output.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "flatten\n",
      "dropout\n",
      "dense\n",
      "model exported ...\n"
     ]
    }
   ],
   "source": [
    "def save_layer_file(id, layer, path):\n",
    "    layer_name = layer.name\n",
    "    layer_type = None\n",
    "    activation_type = \"Linear\"\n",
    "    weights, bias = [[], []]\n",
    "    \n",
    "    layer_config = layer.get_config()\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_type = \"Conv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer_config[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer_type = \"DepthwiseConv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_type = \"Dense\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "        layer_type = \"Flatten\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        layer_type = \"InputLayer\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dropout):\n",
    "        layer_type = \"Dropout\"\n",
    "\n",
    "    else:\n",
    "        print(f\"layer type {type(layer)} not expected..\")\n",
    "\n",
    "    weight_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.weights.npy\"\n",
    "    bias_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.bias.npy\"\n",
    "\n",
    "    np.save(\n",
    "        f\"{path}/\" + weight_path,\n",
    "        weights,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{path}/\" + bias_path,\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "    layerJson = {\n",
    "        \"layerName\": layer_name,\n",
    "        \"layerType\": layer_type,\n",
    "        \"activation\": activation_type,\n",
    "        \"weightPath\": weight_path,\n",
    "        \"biasPath\": bias_path,\n",
    "        \"layer_config\" : layer_config\n",
    "    }\n",
    "\n",
    "    return layerJson\n",
    "\n",
    "\n",
    "\n",
    "save_path = f\"./saved_models/classifier_v2\"\n",
    "modelJson = {\n",
    "    \"modelName\": \"classifier_v2\",\n",
    "    \"layers\": [],\n",
    "}\n",
    "\n",
    "\n",
    "index = 0\n",
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers[1:]:\n",
    "            layerJson = save_layer_file(index, l2, save_path)\n",
    "            modelJson[\"layers\"].append(layerJson)\n",
    "            index += 1\n",
    "    else:\n",
    "        print(l.name)\n",
    "        layerJson = save_layer_file(index, l, save_path)\n",
    "        modelJson[\"layers\"].append(layerJson)\n",
    "        index += 1\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"{save_path}/model.json\", \"w\") as file:\n",
    "    file.write(json.dumps(modelJson))\n",
    "    print(\"model exported ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the numpy dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Dense\n",
    "from Activations import Softmax\n",
    "\n",
    "softmax = Softmax()\n",
    "fc = Dense(\"dense\", activation=softmax)\n",
    "fc.load_weights(\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.weights.npy\",\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_passed!\n"
     ]
    }
   ],
   "source": [
    "# the tensorflow layer and the numpy layer on the same input\n",
    "\n",
    "denseLayer = classifier.get_layer(\"dense\")\n",
    "\n",
    "input_test = np.ones((32, denseLayer.get_weights()[0].shape[0]))\n",
    "\n",
    "o_dut = fc(input_test, False).astype(np.float16).ravel()\n",
    "o_dur = denseLayer(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "np.savetxt(\"dut_fc.txt\", o_dut)\n",
    "np.savetxt(\"dur_fc.txt\", o_dur)\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed. Check dut_fc and dur_fc .txt files for more details.\"\n",
    "\n",
    "\n",
    "print(\"test_passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create conv2D numpy layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded correctly...\n"
     ]
    }
   ],
   "source": [
    "from Layers import Conv2D\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "\n",
    "conv2D_ref = classifier.layers[1].get_layer(\"conv2d\")\n",
    "input_test = np.ones((1, 13, 13, conv2D_ref.weights[0].shape[-2]))\n",
    "\n",
    "\n",
    "npConv2D = Conv2D(\n",
    "    strides=conv2D_ref.get_config()[\"strides\"],\n",
    "    padding=conv2D_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(conv2D_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.bias.npy\",\n",
    ")\n",
    "\n",
    "\n",
    "assert np.all(conv2D_ref.weights[0] == npConv2D.weights), \"weights are different\"\n",
    "assert np.all(conv2D_ref.weights[1] == npConv2D.bias), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "o_dut = npConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = conv2D_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "np.savetxt(\"dut_conv.txt\", o_dut.ravel())\n",
    "np.savetxt(\"dur_conv.txt\", o_dur.ravel())\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_conv.txt and dur_conv.txt files. \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded correctly...\n"
     ]
    }
   ],
   "source": [
    "from Layers import DephtwiseConv2D\n",
    "\n",
    "depthwise_conv2d_ref = classifier.layers[1].get_layer(\"depthwise_conv2d\")\n",
    "\n",
    "npDephtwiseConv2D = DephtwiseConv2D(\n",
    "    strides=depthwise_conv2d_ref.get_config()[\"strides\"],\n",
    "    padding=depthwise_conv2d_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(depthwise_conv2d_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npDephtwiseConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.bias.npy\",\n",
    ")\n",
    "\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[0] == npDephtwiseConv2D.weights\n",
    "), \"weights are different\"\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[1] == npDephtwiseConv2D.bias\n",
    "), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "input_test = np.ones((1, 32, 32, depthwise_conv2d_ref.weights[0].shape[-2]))\n",
    "\n",
    "o_dut = npDephtwiseConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = depthwise_conv2d_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "np.savetxt(\"dut_dconv.txt\", o_dut.ravel())\n",
    "np.savetxt(\"dur_dconv.txt\", o_dur.ravel())\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_dconv.txt and dur_dconv.txt files \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignoring not implemented dropout\n",
      "[<Layers.InputLayer.InputLayer object at 0x7fcd003528c0>, <Layers.DephtwiseConv2D.DephtwiseConv2D object at 0x7fcd926df880>, <Layers.Conv2D.Conv2D object at 0x7fcd926dfb50>, <Layers.Conv2D.Conv2D object at 0x7fcd001dfdc0>, <Layers.Flatten.Flatten object at 0x7fcd001dd6c0>, <Layers.Dense.Dense object at 0x7fcd001de7a0>]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from NumpyModel import Model\n",
    "from Layers import InputLayer, Conv2D, Dense, DephtwiseConv2D, Flatten\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classifier_model_path = \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/\"\n",
    "\n",
    "modelJson = json.load(open(classifier_model_path + \"model.json\"))\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "for layerConfig in modelJson[\"layers\"]:\n",
    "    if layerConfig[\"layerType\"] == \"InputLayer\":\n",
    "        layer = InputLayer(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Conv2D\":\n",
    "        layer = Conv2D(\n",
    "            padding=layerConfig[\"layer_config\"][\"padding\"],\n",
    "            strides=layerConfig[\"layer_config\"][\"strides\"],\n",
    "            name=layerConfig[\"layerName\"],\n",
    "        )\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"DepthwiseConv2D\":\n",
    "        layer = DephtwiseConv2D(\n",
    "            padding=layerConfig[\"layer_config\"][\"padding\"],\n",
    "            strides=layerConfig[\"layer_config\"][\"strides\"],\n",
    "            name=layerConfig[\"layerName\"],\n",
    "        )\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dense\":\n",
    "        layer = Dense(layerConfig[\"layerName\"])\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = activation_from_name(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Flatten\":\n",
    "        layer = Flatten(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dropout\":\n",
    "        print(\"ignoring not implemented dropout\")\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(layerConfig)\n",
    "        raise NotImplementedError(layerConfig[\"layerName\"])\n",
    "\n",
    "    model.layers.append(layer)\n",
    "\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test passed...\n"
     ]
    }
   ],
   "source": [
    "input_test = np.zeros(\n",
    "    shape=[\n",
    "        1,\n",
    "    ]\n",
    "    + list(classifier.layers[0].get_config()[\"batch_input_shape\"][1:])\n",
    ")\n",
    "\n",
    "o_dut_model = classifier(input_test).numpy().astype(np.float16)\n",
    "o_ref_model = model(input_test, training=False).astype(np.float16)\n",
    "\n",
    "assert np.all(o_dut_model == o_ref_model), \"val test failed. Check values\"\n",
    "\n",
    "print(\"model test passed...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
