{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 18:52:25.897076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 18:52:26.117451: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 18:52:26.861477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-06 18:52:26.861575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-06 18:52:26.861582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 18:52:27.907915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-06 18:52:27.945446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-01-06 18:52:27.945470: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-06 18:52:27.945794: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 16, 16, 16)        6840      \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 8)           1160      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,565\n",
      "Trainable params: 3,725\n",
      "Non-trainable params: 6,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model = tf.keras.models.load_model(\n",
    "    r\"./saved_models/encoder_v3\",\n",
    "    custom_objects={\"custom_loss\": None},\n",
    ")\n",
    "\n",
    "autoencoder_model.trainable = False\n",
    "model_input = autoencoder_model.layers[0].input\n",
    "encoder_output = autoencoder_model.get_layer(\"encoder_output\").output\n",
    "encoder = keras.Model(inputs=[model_input], outputs=[encoder_output])\n",
    "\n",
    "x = x_in = keras.layers.Input((256, 256, 3))\n",
    "\n",
    "encoder_output = encoder(x)\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "    8,\n",
    "    kernel_size=3,\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    ")(encoder_output)\n",
    "x = keras.layers.Flatten()(x) #(encoder_output)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(5, \"softmax\")(x)\n",
    "\n",
    "# create model\n",
    "classifier = keras.Model(inputs=[x_in], outputs=[x])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.load_model(r\"./saved_models/classifier_v2\")\n",
    "classifier.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f46d7727fa0>\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7f465f925f00>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f465f9253c0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f465f9245b0>\n",
      "model\n",
      "conv2d\n",
      "flatten\n",
      "dropout\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers:\n",
    "            print(l2)\n",
    "\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights as numpy file\n",
    "\n",
    "the name of the file indicates the 'type' of the layer, the layer 'name', and 'activation', separeted by '.'.\\\n",
    "eg: Conv2D.encoder_output.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "conv2d\n",
      "flatten\n",
      "dropout\n",
      "dense\n",
      "model exported ...\n"
     ]
    }
   ],
   "source": [
    "def save_layer_file(id, layer, path):\n",
    "    layer_name = layer.name\n",
    "    layer_type = None\n",
    "    activation_type = \"Linear\"\n",
    "    weights, bias = [[], []]\n",
    "    \n",
    "    layer_config = layer.get_config()\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_type = \"Conv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer_config[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer_type = \"DepthwiseConv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_type = \"Dense\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "        layer_type = \"Flatten\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        layer_type = \"InputLayer\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dropout):\n",
    "        layer_type = \"Dropout\"\n",
    "\n",
    "    else:\n",
    "        print(f\"layer type {type(layer)} not expected..\")\n",
    "\n",
    "    weight_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.weights.npy\"\n",
    "    bias_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.bias.npy\"\n",
    "\n",
    "    np.save(\n",
    "        f\"{path}/\" + weight_path,\n",
    "        weights,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{path}/\" + bias_path,\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "    layerJson = {\n",
    "        \"layerName\": layer_name,\n",
    "        \"layerType\": layer_type,\n",
    "        \"activation\": activation_type,\n",
    "        \"weightPath\": weight_path,\n",
    "        \"biasPath\": bias_path,\n",
    "        \"layer_config\" : layer_config\n",
    "    }\n",
    "\n",
    "    return layerJson\n",
    "\n",
    "\n",
    "\n",
    "save_path = f\"./saved_models/classifier_v2\"\n",
    "modelJson = {\n",
    "    \"modelName\": \"classifier_v2\",\n",
    "    \"layers\": [],\n",
    "}\n",
    "\n",
    "\n",
    "index = 0\n",
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers[1:]:\n",
    "            layerJson = save_layer_file(index, l2, save_path)\n",
    "            modelJson[\"layers\"].append(layerJson)\n",
    "            index += 1\n",
    "    else:\n",
    "        print(l.name)\n",
    "        layerJson = save_layer_file(index, l, save_path)\n",
    "        modelJson[\"layers\"].append(layerJson)\n",
    "        index += 1\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"{save_path}/model.json\", \"w\") as file:\n",
    "    file.write(json.dumps(modelJson))\n",
    "    print(\"model exported ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the numpy dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Dense, Softmax\n",
    "\n",
    "softmax = Softmax()\n",
    "fc = Dense(\"dense\", activation=softmax)\n",
    "fc.load_weights(\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/7.Dense.dense.softmax.weights.npy\",\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/7.Dense.dense.softmax.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_passed!\n"
     ]
    }
   ],
   "source": [
    "# the tensorflow layer and the numpy layer on the same input\n",
    "\n",
    "denseLayer = classifier.get_layer(\"dense\")\n",
    "\n",
    "input_test = np.ones((32, denseLayer.get_weights()[0].shape[0]))\n",
    "\n",
    "o_dut = fc(input_test, False).astype(np.float16).ravel()\n",
    "o_dur = denseLayer(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "np.savetxt(\"dut_fc.txt\", o_dut)\n",
    "np.savetxt(\"dur_fc.txt\", o_dur)\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed\"\n",
    "\n",
    "print(\"test_passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create conv2D numpy layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Conv2D, Tanh\n",
    "\n",
    "conv2D_ref = classifier.get_layer(\"conv2d\")\n",
    "input_test = np.ones((1, 13, 13, conv2D_ref.weights[0].shape[-2]))\n",
    "\n",
    "\n",
    "npConv2D = Conv2D(\n",
    "    strides=conv2D_ref.get_config()[\"strides\"],\n",
    "    padding=conv2D_ref.get_config()[\"padding\"],\n",
    "    activation=None,\n",
    ")\n",
    "npConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/4.Conv2D.conv2d.linear.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/4.Conv2D.conv2d.linear.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed!\n"
     ]
    }
   ],
   "source": [
    "o_dut = npConv2D(input_test, training=False).astype(np.float16).ravel()\n",
    "o_dur = conv2D_ref(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "\n",
    "np.savetxt(\"dut_conv.txt\", o_dut)\n",
    "np.savetxt(\"dur_conv.txt\", o_dur)\n",
    "\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed. Check dut_conv.txt and dur_conv.txt files \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13, 13, 3)\n"
     ]
    }
   ],
   "source": [
    "from Layers import DephtwiseConv2D, Tanh\n",
    "\n",
    "depthwise_conv2d_ref = classifier.get_layer(\"model\").get_layer(\"depthwise_conv2d\")\n",
    "input_test = np.ones((1, 13, 13, depthwise_conv2d_ref.weights[0].shape[-2]))\n",
    "\n",
    "print(input_test.shape)\n",
    "\n",
    "npDephtwiseConv2D = DephtwiseConv2D(\n",
    "    strides=depthwise_conv2d_ref.get_config()[\"strides\"],\n",
    "    padding=depthwise_conv2d_ref.get_config()[\"padding\"],\n",
    "    activation=None,\n",
    ")\n",
    "npDephtwiseConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3,3) (3,3,16) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m o_dut \u001b[39m=\u001b[39m npConv2D(input_test, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat16)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m o_dur \u001b[39m=\u001b[39m conv2D_ref(input_test)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat16)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/export_classifier.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39msavetxt(\u001b[39m\"\u001b[39m\u001b[39mdut_dconv.txt\u001b[39m\u001b[39m\"\u001b[39m, o_dut)\n",
      "File \u001b[0;32m~/Desktop/dnn_processor/reference_algorithm/neural_network/Layers/Conv2D.py:78\u001b[0m, in \u001b[0;36mConv2D.__call__\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mConv2D trainin not implemented\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     outputs \u001b[39m=\u001b[39m convolution(\n\u001b[1;32m     79\u001b[0m         inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrides, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(outputs, training)\n",
      "File \u001b[0;32m~/Desktop/dnn_processor/reference_algorithm/neural_network/Layers/Conv2D.py:57\u001b[0m, in \u001b[0;36mconvolution\u001b[0;34m(inputs, filters, bias, strides, padding)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 input_region \u001b[39m=\u001b[39m padded_inputs[\n\u001b[1;32m     50\u001b[0m                     b,\n\u001b[1;32m     51\u001b[0m                     h \u001b[39m*\u001b[39m stride_h : h \u001b[39m*\u001b[39m stride_h \u001b[39m+\u001b[39m fh,\n\u001b[1;32m     52\u001b[0m                     w \u001b[39m*\u001b[39m stride_w : w \u001b[39m*\u001b[39m stride_w \u001b[39m+\u001b[39m fw,\n\u001b[1;32m     53\u001b[0m                     :,\n\u001b[1;32m     54\u001b[0m                 ]\n\u001b[1;32m     55\u001b[0m                 \u001b[39m# Perform element-wise multiplication and sum using vectorized operations\u001b[39;00m\n\u001b[1;32m     56\u001b[0m                 output[b, h, w, m] \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 57\u001b[0m                     np\u001b[39m.\u001b[39msum(input_region \u001b[39m*\u001b[39;49m filters[:, :, :, m]) \u001b[39m+\u001b[39m bias[m]\n\u001b[1;32m     58\u001b[0m                 )\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3,3) (3,3,16) "
     ]
    }
   ],
   "source": [
    "o_dut = npConv2D(input_test, training=False).astype(np.float16).ravel()\n",
    "o_dur = conv2D_ref(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "\n",
    "np.savetxt(\"dut_dconv.txt\", o_dut)\n",
    "np.savetxt(\"dur_dconv.txt\", o_dur)\n",
    "\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed. Check dut_conv.txt and dur_conv.txt files \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from NumpyModel import Model\n",
    "from Layers import InputLayer, Conv2D, Dense, DephtwiseConv2D, Flatten, Softmax\n",
    "\n",
    "\n",
    "classifier_model_path = \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/\"\n",
    "\n",
    "modelJson = json.load(open(classifier_model_path + \"model.json\"))\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "def create_activation(activation_name):\n",
    "    if activation_name == \"softmax\":\n",
    "        return Softmax()\n",
    "    elif activation_name == \"tanh\":\n",
    "        return Tanh()\n",
    "    elif activation_name == \"linear\":\n",
    "        return None\n",
    "    else:\n",
    "        raise TypeError(f\"unknow activation name {activation_name}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "for layerConfig in modelJson[\"layers\"]:\n",
    "    if layerConfig[\"layerType\"] == \"InputLayer\":\n",
    "        layer = InputLayer(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Conv2D\":\n",
    "        layer = Conv2D(\n",
    "            padding=layerConfig[\"layer_config\"][\"padding\"],\n",
    "            strides=layerConfig[\"layer_config\"][\"strides\"],\n",
    "            name=layerConfig[\"layerName\"],\n",
    "        )\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "\n",
    "        layer.activation = create_activation(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"DepthwiseConv2D\":\n",
    "        layer = DephtwiseConv2D(layerConfig[\"layerName\"])\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = create_activation(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dense\":\n",
    "        layer = Dense(layerConfig[\"layerName\"])\n",
    "        layer.load_weights(\n",
    "            classifier_model_path + layerConfig[\"weightPath\"],\n",
    "            classifier_model_path + layerConfig[\"biasPath\"],\n",
    "        )\n",
    "        layer.activation = create_activation(layerConfig[\"activation\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Flatten\":\n",
    "        layer = Flatten(layerConfig[\"layerName\"])\n",
    "\n",
    "    elif layerConfig[\"layerType\"] == \"Dropout\":\n",
    "        print(\"ignoring not implemented dropout\")\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(layerConfig)\n",
    "        raise NotImplementedError(layerConfig[\"layerName\"])\n",
    "\n",
    "    model.layers.append(layer)\n",
    "\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
