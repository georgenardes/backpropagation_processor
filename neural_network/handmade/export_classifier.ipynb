{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:36:51.258654: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 19:36:51.282338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 19:36:51.282361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 19:36:51.283081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 19:36:51.287507: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 19:36:51.719993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:36:52.392836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:52.416900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:52.417048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:52.418077: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:52.418187: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:52.418237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:53.083993: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:53.084102: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:53.084159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 19:36:53.084210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "classifier_model_path = r\"/home/webphy/Desktop/dnn_processor/neural_network/handmade/saved_models/manual_test_4x/model.h5\"\n",
    "classifier = tf.keras.models.load_model(classifier_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "conv2d_3\n",
      "activation_2\n",
      "conv2d_4\n",
      "activation_3\n",
      "conv2d_5\n",
      "flatten_1\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers:\n",
    "            print(l2)\n",
    "    else:\n",
    "        print(l.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model weights as numpy file\n",
    "\n",
    "the name of the file indicates the 'type' of the layer, the layer 'name', and 'activation', separeted by '.'.\\\n",
    "eg: Conv2D.encoder_output.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "conv2d_3\n",
      "activation_2\n",
      "conv2d_4\n",
      "activation_3\n",
      "conv2d_5\n",
      "flatten_1\n",
      "dense_1\n",
      "model exported ...\n"
     ]
    }
   ],
   "source": [
    "def save_layer_file(id, layer, path):\n",
    "    layer_name = layer.name\n",
    "    layer_type = None\n",
    "    activation_type = \"Linear\"\n",
    "    weights, bias = [[], []]\n",
    "    \n",
    "    layer_config = layer.get_config()\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer_type = \"Conv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer_config[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "        layer_type = \"DepthwiseConv2D\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dense):\n",
    "        layer_type = \"Dense\"\n",
    "        weights, bias = layer.get_weights()\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Activation):\n",
    "        layer_type = \"Activation\"\n",
    "        activation_type = layer.get_config()[\"activation\"]\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "        layer_type = \"Flatten\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        layer_type = \"InputLayer\"\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.Dropout):\n",
    "        layer_type = \"Dropout\"\n",
    "\n",
    "    else:\n",
    "        print(f\"layer type {type(layer)} not expected..\")\n",
    "\n",
    "    weight_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.weights.npy\"\n",
    "    bias_path = f\"{id}.{layer_type}.{layer_name}.{activation_type}.bias.npy\"\n",
    "\n",
    "    np.save(\n",
    "        f\"{path}/\" + weight_path,\n",
    "        weights,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{path}/\" + bias_path,\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "    layerJson = {\n",
    "        \"layerName\": layer_name,\n",
    "        \"layerType\": layer_type,\n",
    "        \"activation\": activation_type,\n",
    "        \"weightPath\": weight_path,\n",
    "        \"biasPath\": bias_path,\n",
    "        \"layer_config\" : layer_config\n",
    "    }\n",
    "\n",
    "    return layerJson\n",
    "\n",
    "\n",
    "\n",
    "save_path = f\"./saved_models/classifier_v3\"\n",
    "modelJson = {\n",
    "    \"modelName\": \"classifier_v3\",\n",
    "    \"layers\": [],\n",
    "}\n",
    "\n",
    "\n",
    "index = 0\n",
    "for l in classifier.layers:\n",
    "    if isinstance(l, tf.keras.Model):\n",
    "        for l2 in l.layers[1:]:\n",
    "            layerJson = save_layer_file(index, l2, save_path)\n",
    "            modelJson[\"layers\"].append(layerJson)\n",
    "            index += 1\n",
    "    else:\n",
    "        print(l.name)\n",
    "        layerJson = save_layer_file(index, l, save_path)\n",
    "        modelJson[\"layers\"].append(layerJson)\n",
    "        index += 1\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"{save_path}/model.json\", \"w\") as file:\n",
    "    file.write(json.dumps(modelJson))\n",
    "    print(\"model exported ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the numpy dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Dense\n",
    "from Activations import Softmax\n",
    "\n",
    "softmax = Softmax()\n",
    "fc = Dense(\"dense\", activation=softmax)\n",
    "fc.load_weights(\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.weights.npy\",\n",
    "    \"/home/george/Desktop/dnn_processor/reference_algorithm/neural_network/saved_models/classifier_v2/6.Dense.dense.softmax.bias.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dense/softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tensorflow layer and the numpy layer on the same input\n",
    "\n",
    "denseLayer = classifier.get_layer(\"dense\")\n",
    "\n",
    "input_test = np.ones((32, denseLayer.get_weights()[0].shape[0]))\n",
    "\n",
    "o_dut = fc(input_test, False).astype(np.float16).ravel()\n",
    "o_dur = denseLayer(input_test).numpy().astype(np.float16).ravel()\n",
    "\n",
    "np.savetxt(\"dut_fc.txt\", o_dut)\n",
    "np.savetxt(\"dur_fc.txt\", o_dur)\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(o_dut == o_dur), f\"val test failed. Check dut_fc and dur_fc .txt files for more details.\"\n",
    "\n",
    "\n",
    "print(\"test_passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create conv2D numpy layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import Conv2D\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "\n",
    "conv2D_ref = classifier.layers[1].get_layer(\"conv2d\")\n",
    "input_test = np.ones((1, 13, 13, conv2D_ref.weights[0].shape[-2]))\n",
    "\n",
    "\n",
    "npConv2D = Conv2D(\n",
    "    strides=conv2D_ref.get_config()[\"strides\"],\n",
    "    padding=conv2D_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(conv2D_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/2.Conv2D.conv2d.tanh.bias.npy\",\n",
    ")\n",
    "\n",
    "\n",
    "assert np.all(conv2D_ref.weights[0] == npConv2D.weights), \"weights are different\"\n",
    "assert np.all(conv2D_ref.weights[1] == npConv2D.bias), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_dut = npConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = conv2D_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "np.savetxt(\"dut_conv.txt\", o_dut.ravel())\n",
    "np.savetxt(\"dur_conv.txt\", o_dur.ravel())\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_conv.txt and dur_conv.txt files. \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import DephtwiseConv2D\n",
    "\n",
    "depthwise_conv2d_ref = classifier.layers[1].get_layer(\"depthwise_conv2d\")\n",
    "\n",
    "npDephtwiseConv2D = DephtwiseConv2D(\n",
    "    strides=depthwise_conv2d_ref.get_config()[\"strides\"],\n",
    "    padding=depthwise_conv2d_ref.get_config()[\"padding\"],\n",
    "    activation=activation_from_name(depthwise_conv2d_ref.get_config()[\"activation\"]),\n",
    ")\n",
    "npDephtwiseConv2D.load_weights(\n",
    "    weight_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.weights.npy\",\n",
    "    bias_path=\"./saved_models/classifier_v2/1.DepthwiseConv2D.depthwise_conv2d.linear.bias.npy\",\n",
    ")\n",
    "\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[0] == npDephtwiseConv2D.weights\n",
    "), \"weights are different\"\n",
    "assert np.all(\n",
    "    depthwise_conv2d_ref.weights[1] == npDephtwiseConv2D.bias\n",
    "), \"bias are different\"\n",
    "print(\"weights loaded correctly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test depthwise convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = np.ones((1, 32, 32, depthwise_conv2d_ref.weights[0].shape[-2]))\n",
    "\n",
    "o_dut = npDephtwiseConv2D(input_test, training=False).astype(np.float16)\n",
    "o_dur = depthwise_conv2d_ref(input_test).numpy().astype(np.float16)\n",
    "\n",
    "np.savetxt(\"dut_dconv.txt\", o_dut.ravel())\n",
    "np.savetxt(\"dur_dconv.txt\", o_dur.ravel())\n",
    "\n",
    "assert o_dut.shape == o_dur.shape, f\"shape test failed. { o_dut.shape} != {o_dur.shape}\"\n",
    "assert np.all(\n",
    "    o_dut == o_dur\n",
    "), f\"val test failed. Check dut_dconv.txt and dur_dconv.txt files \"\n",
    "\n",
    "print(\"test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Layers.InputLayer.InputLayer object at 0x7f010c0e3e80>, <Layers.Conv2D.Conv2D object at 0x7f0044c21cc0>, <Layers.ActivationLayer.ActivationLayer object at 0x7f0044c21c30>, <Layers.Conv2D.Conv2D object at 0x7f0044369960>, <Layers.ActivationLayer.ActivationLayer object at 0x7f004436a3e0>, <Layers.Conv2D.Conv2D object at 0x7f0044369ea0>, <Layers.Flatten.Flatten object at 0x7f0044369e70>, <Layers.Dense.Dense object at 0x7f004436a0b0>]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from NumpyModel import Model\n",
    "from Layers import InputLayer, Conv2D, Dense, DephtwiseConv2D, Flatten, ActivationLayer\n",
    "from Activations.ActivationFactory import activation_from_name\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classifier_model_path = \"/home/webphy/Desktop/dnn_processor/neural_network/handmade/saved_models/classifier_v3/\"\n",
    "classifier = tf.keras.models.load_model(\n",
    "    r\"/home/webphy/Desktop/dnn_processor/neural_network/handmade/saved_models/manual_test_4x/model.h5\"\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.load_model(classifier_model_path)\n",
    "\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:37:03.770214: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m input_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m      2\u001b[0m     shape\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m     ]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(classifier\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_input_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m o_dut_model \u001b[38;5;241m=\u001b[39m classifier(input_test)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m----> 9\u001b[0m o_ref_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(o_dut_model \u001b[38;5;241m==\u001b[39m o_ref_model), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval test failed. Check values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel test passed...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "input_test = np.zeros(\n",
    "    shape=[\n",
    "        1,\n",
    "    ]\n",
    "    + list(classifier.layers[0].get_config()[\"batch_input_shape\"][1:])\n",
    ")\n",
    "\n",
    "o_dut_model = classifier(input_test).numpy().astype(np.float16)\n",
    "o_ref_model = model(input_test, training=False).astype(np.float16)\n",
    "\n",
    "assert np.all(o_dut_model == o_ref_model), \"val test failed. Check values\"\n",
    "\n",
    "print(\"model test passed...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
