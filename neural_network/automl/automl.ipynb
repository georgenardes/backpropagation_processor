{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/\")  # just to enable `dataset`\n",
    "sys.path.append(\n",
    "    \"/home/webphy/Desktop/dnn_processor/dataset/\"\n",
    ")  # just to enable `dataset`\n",
    "\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import dataset\n",
    "import numpy as np\n",
    "import keras\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  define constants and create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTRIALS = 300\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "train_images_rgx = \"../../dataset/resized_dataset_texturas_v2/*/*.jpeg\"\n",
    "valid_images_rgx = \"../../dataset/resized_dataset_texturas_v2_test/*/*.jpeg\"\n",
    "\n",
    "layer_options = [\"Conv2D\", \"Depthwise2D\", \"Pointwise2D\"]\n",
    "activation_options = [\"linear\", \"relu\", \"tanh\"]\n",
    "filter_size_options = [3, 4, 5, 8, 16]\n",
    "\n",
    "train_dataset, val_dataset, num_classes = dataset.create_datasets(\n",
    "    train_images_rgx, valid_images_rgx, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define create model function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_filter_size(fs, ih):\n",
    "    return min(fs, ih)\n",
    "\n",
    "\n",
    "def create_layer(trial, layer_type, layer_id, max_stride, input_h_size):\n",
    "    if layer_type == \"Conv2D\":\n",
    "        num_filters = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_conv2d_filters\", 4, 32, step=4\n",
    "        )\n",
    "        filter_size = trial.suggest_categorical(\n",
    "            f\"layer_{layer_id}_conv2d_fsize\", filter_size_options\n",
    "        )\n",
    "\n",
    "        stride_size = trial.suggest_int(f\"layer_{layer_id}_conv2d_ssize\", 1, max_stride)\n",
    "        layer = layers.Conv2D(\n",
    "            num_filters, clip_filter_size(filter_size, input_h_size), stride_size\n",
    "        )\n",
    "\n",
    "    elif layer_type == \"Depthwise2D\":\n",
    "        filter_size = trial.suggest_categorical(\n",
    "            f\"layer_{layer_id}_dwconv2d_fsize\", filter_size_options\n",
    "        )\n",
    "        stride_size = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_dwconv2d_ssize\", 1, max_stride\n",
    "        )\n",
    "        layer = layers.DepthwiseConv2D(\n",
    "            clip_filter_size(filter_size, input_h_size), stride_size\n",
    "        )\n",
    "\n",
    "    elif layer_type == \"Pointwise2D\":\n",
    "        num_filters = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_pwconv2d_filters\", 4, 32, step=4\n",
    "        )\n",
    "        stride_size = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_pwconv2d_ssize\", 1, max_stride\n",
    "        )\n",
    "        layer = layers.Conv2D(num_filters, 1, stride_size)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def create_augmentation_layers(trial, x):\n",
    "    # augmix_severity = trial.suggest_float(\"augmix_severity\", 0.0, 0.5)\n",
    "    brightness_factor = trial.suggest_float(\"brightness_factor\", 0, 0.2)\n",
    "    gaussian_noise_factor = trial.suggest_float(\"gaussian_noise_factor\", 0, 0.2)\n",
    "    translate_factor = trial.suggest_float(\"translate_factor\", 0, 0.2)\n",
    "\n",
    "    # x = keras_cv.layers.AugMix(value_range=(0, 1), severity=augmix_severity)(x)\n",
    "    x = layers.RandomBrightness(brightness_factor, (0, 1.0))(x)\n",
    "    x = layers.RandomFlip()(x)\n",
    "    x = layers.RandomTranslation(translate_factor, translate_factor)(x)\n",
    "    x = layers.GaussianNoise(gaussian_noise_factor)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # add the input layer\n",
    "    x = x_in = layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = create_augmentation_layers(trial, x)\n",
    "\n",
    "    # suggent a number of layer\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 4])\n",
    "\n",
    "    # limits the stride\n",
    "    max_stride = 16 // num_layers\n",
    "\n",
    "    # convolutional layers\n",
    "    for i in range(num_layers):\n",
    "        layer_selected = trial.suggest_categorical(f\"layer_{i}\", layer_options)\n",
    "        layer = create_layer(\n",
    "            trial, layer_selected, i, max_stride, input_h_size=x.shape[1]\n",
    "        )\n",
    "        x = layer(x)\n",
    "        act_selected = trial.suggest_categorical(f\"activation_{i}\", activation_options)\n",
    "        x = layers.Activation(act_selected)(x)\n",
    "\n",
    "    # output layer\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(trial.suggest_float(\"output_dropout\", 0.3, 0.6))(x)\n",
    "    x = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(x_in, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "class MockTrial:\n",
    "    def suggest_int(self, name, min, max, step=None, log=False):\n",
    "        return np.random.randint(min, max)\n",
    "\n",
    "    def suggest_float(self, name, min, max, step=None, log=False):\n",
    "        return np.random.uniform(min, max)\n",
    "\n",
    "    def suggest_categorical(self, name, options):\n",
    "        print(name)\n",
    "        return options[np.random.randint(0, len(options) - 1)]\n",
    "\n",
    "    def suggest_discrete_uniform(self, name, min, max, q):\n",
    "        return (np.random.randint(min, max) // q) * q\n",
    "\n",
    "model = create_model(MockTrial())\n",
    "model.build(input_shape=(BATCH_SIZE, 256, 256, 3))\n",
    "model.summary()\n",
    "model.save(\"saved_models/test/\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial):\n",
    "    lr = trial.suggest_float(\"lr_inicial\", 1e-4, 2e-3, log=True)\n",
    "    optimizer = keras.optimizers.Adam(lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_model_checkpointer(save_path):\n",
    "    return keras.callbacks.ModelCheckpoint(\n",
    "        save_path + \"weights/\",\n",
    "        \"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def crate_early_stopper():\n",
    "    return keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0.1,\n",
    "        patience=20,\n",
    "        verbose=0,\n",
    "        mode=\"max\",\n",
    "        start_from_epoch=50,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    BATCH_SIZE = trial.suggest_int(\"batchsize\", 32, 128, step=32)\n",
    "    \n",
    "    # load data\n",
    "    train_dataset, val_dataset, num_classes = dataset.create_datasets(\n",
    "        train_images_rgx, valid_images_rgx, BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Build model and optimizer.\n",
    "    model = create_model(trial)\n",
    "    assert isinstance(model, keras.Model), \"model is not a model\"\n",
    "\n",
    "    optimizer = create_optimizer(trial)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer, loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # crate model checkpointer\n",
    "    saved_best_model_path = f\"saved_models/{EXP_ID}/best_model_t{trial._trial_id}/\"\n",
    "    model.save(saved_best_model_path, True, \"tf\")  # save all model\n",
    "\n",
    "    model_chkp = create_model_checkpointer(saved_best_model_path)\n",
    "    early_stopper = crate_early_stopper()\n",
    "\n",
    "    # Training and validating cycle.\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[model_chkp, early_stopper],\n",
    "        verbose=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # load best model\n",
    "    model.load_weights(saved_best_model_path + \"weights/\")    \n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    # Return best model validation accuracy.\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "def search():\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(),\n",
    "    )\n",
    "    study.optimize(objective, n_trials=NTRIALS)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = \"exp4_with_aug\"\n",
    "keras.utils.disable_interactive_logging()\n",
    "\n",
    "# start searching for a model\n",
    "study = search()\n",
    "\n",
    "# save the study\n",
    "now = datetime.now()\n",
    "joblib.dump(study, \"saved_studies/\" + now.strftime(\"%Y:%m:%d:%H:%M:%S\") + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "trial = study.best_trial\n",
    "print(f\"Best trial id: {trial._trial_id}\")\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(\n",
    "    study,\n",
    "    [\n",
    "        \"lr_inicial\",\n",
    "        \"num_layers\",\n",
    "        \"layer_0\",\n",
    "        \"activation_0\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.load_model(\"/home/webphy/Desktop/dnn_processor/neural_network/automl/saved_models/exp2_with_aug/best_model_t185\")\n",
    "\n",
    "for l in model.layers:\n",
    "    print(l.get_config())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
