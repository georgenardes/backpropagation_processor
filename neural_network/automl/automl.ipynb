{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 19:20:14.680016: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-28 19:20:14.704462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 19:20:14.704484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 19:20:14.705391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 19:20:14.710261: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 19:20:15.127042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/webphy/Desktop/dnn_processor/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/\")  # just to enable `dataset`\n",
    "sys.path.append(\n",
    "    \"/home/webphy/Desktop/dnn_processor/dataset/\"\n",
    ")  # just to enable `dataset`\n",
    "\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import dataset\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 19:20:15.606957: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:15.631500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:15.631619: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:15.632773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: <_ParallelBatchDataset element_spec=(TensorSpec(shape=(64, 256, 256, 3), dtype=tf.float16, name=None), TensorSpec(shape=(64, 5), dtype=tf.float32, name=None))>\n",
      "Val Dataset: <_ParallelBatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float16, name=None), TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L355\n",
      "2024-01-28 19:20:15.632846: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:15.632892: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:16.304677: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:16.304772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:16.304826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 19:20:16.304874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9736 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_images_rgx = \"../../dataset/resized_dataset_texturas_v2/*/*.jpeg\"\n",
    "valid_images_rgx = \"../../dataset/resized_dataset_texturas_v2_test/*/*.jpeg\"\n",
    "\n",
    "train_dataset, val_dataset, num_classes = dataset.create_datasets(\n",
    "    train_images_rgx, valid_images_rgx, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define create model function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "layer_options = [\"Conv2D\", \"Depthwise2D\", \"Pointwise2D\"]\n",
    "activation_options = [\"linear\", \"relu\", \"tanh\"]\n",
    "filter_size_options = [3, 4, 5, 8, 16]\n",
    "\n",
    "\n",
    "def clip_filter_size(fs, ih):\n",
    "    return min(fs, ih)\n",
    "\n",
    "\n",
    "def create_layer(trial, layer_type, layer_id, max_stride, input_h_size):\n",
    "    if layer_type == \"Conv2D\":\n",
    "        num_filters = trial.suggest_int(f\"layer_{layer_id}_conv2d_filters\", 4, 32, step=4)\n",
    "        filter_size = trial.suggest_categorical(\n",
    "            f\"layer_{layer_id}_conv2d_fsize\", filter_size_options\n",
    "        )\n",
    "\n",
    "        stride_size = trial.suggest_int(f\"layer_{layer_id}_conv2d_ssize\", 1, max_stride)\n",
    "        layer = layers.Conv2D(\n",
    "            num_filters, clip_filter_size(filter_size, input_h_size), stride_size\n",
    "        )\n",
    "\n",
    "    elif layer_type == \"Depthwise2D\":\n",
    "        filter_size = trial.suggest_categorical(\n",
    "            f\"layer_{layer_id}_dwconv2d_fsize\", filter_size_options\n",
    "        )\n",
    "        stride_size = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_dwconv2d_ssize\", 1, max_stride\n",
    "        )\n",
    "        layer = layers.DepthwiseConv2D(\n",
    "            clip_filter_size(filter_size, input_h_size), stride_size\n",
    "        )\n",
    "\n",
    "    elif layer_type == \"Pointwise2D\":\n",
    "        num_filters = trial.suggest_int(f\"layer_{layer_id}_pwconv2d_filters\", 4, 32, step=4)\n",
    "        stride_size = trial.suggest_int(\n",
    "            f\"layer_{layer_id}_pwconv2d_ssize\", 1, max_stride\n",
    "        )\n",
    "        layer = layers.Conv2D(num_filters, 1, stride_size)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # add the input layer\n",
    "    x = x_in = layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "    # suggent a number of layer\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 4])\n",
    "\n",
    "    # limits the stride\n",
    "    max_stride = 16 // num_layers\n",
    "\n",
    "    # convolutional layers\n",
    "    for i in range(num_layers):\n",
    "        layer_selected = trial.suggest_categorical(f\"layer_{i}\", layer_options)\n",
    "        layer = create_layer(\n",
    "            trial, layer_selected, i, max_stride, input_h_size=x.shape[1]\n",
    "        )\n",
    "        x = layer(x)\n",
    "        act_selected = trial.suggest_categorical(f\"activation_{i}\", activation_options)\n",
    "        x = layers.Activation(act_selected)(x)\n",
    "\n",
    "    # output layer\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(x_in, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "class MockTrial:\n",
    "    def suggest_int(self, name, min, max, log=False):\n",
    "        return np.random.randint(min, max)\n",
    "\n",
    "    def suggest_categorical(self, name, options):\n",
    "        print(name)\n",
    "        return options[np.random.randint(0, len(options) - 1)]\n",
    "\n",
    "    def suggest_discrete_uniform(self, name, min, max, q):\n",
    "        return (np.random.randint(min, max) // q) * q\n",
    "\n",
    "model = create_model(MockTrial())\n",
    "model.build(input_shape=(BATCH_SIZE, 256, 256, 3))\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial):\n",
    "    lr = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = keras.optimizers.Adam(lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_model_checkpointer(save_path):\n",
    "    return keras.callbacks.ModelCheckpoint(\n",
    "        save_path,\n",
    "        \"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,    \n",
    "        save_weights_only=True    \n",
    "    )\n",
    "\n",
    "\n",
    "def crate_early_stopper():\n",
    "    return keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0.1,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"max\",                \n",
    "        start_from_epoch=50,\n",
    "    )\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    EPOCHS = 100\n",
    "\n",
    "    # Build model and optimizer.\n",
    "    model = create_model(trial)\n",
    "    assert isinstance(model, keras.Model), \"model is not a model\"\n",
    "\n",
    "    optimizer = create_optimizer(trial)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer, loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # crate model checkpointer\n",
    "    saved_best_model_path = f\"saved_models/best_model_t{trial._trial_id}/\"\n",
    "    model.save(saved_best_model_path, True, \"tf\") # save all model \n",
    "\n",
    "    model_chkp = create_model_checkpointer(saved_best_model_path)\n",
    "    early_stopper = crate_early_stopper()\n",
    "\n",
    "    # Training and validating cycle.\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[model_chkp, early_stopper],\n",
    "        verbose=\"0\",\n",
    "    )\n",
    "\n",
    "    # load best model\n",
    "    best_model = keras.models.load_model(saved_best_model_path)\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = best_model.evaluate(val_dataset, verbose=0)\n",
    "\n",
    "    # Return best model validation accuracy.\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "def search():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-28 19:20:16,541] A new study created in memory with name: no-name-9059ce5f-ba8c-4f2e-b0a1-719348a0b367\n",
      "/tmp/ipykernel_926437/2502342074.py:14: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  num_filters = trial.suggest_int(f\"layer_{layer_id}_conv2d_filters\", 4, 32, 4)\n",
      "/tmp/ipykernel_926437/2502342074.py:36: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  num_filters = trial.suggest_int(f\"layer_{layer_id}_pwconv2d_filters\", 4, 32, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/best_model_t0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/best_model_t0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 19:20:18.299371: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
