{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 19:44:06.951832: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-15 19:44:06.975286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-15 19:44:06.975309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-15 19:44:06.976115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-15 19:44:06.980297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 19:44:07.409191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/\")  # just to enable `dataset`\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/dataset/\")  # just to enable `dataset`\n",
    "\n",
    "\n",
    "import dataset\n",
    "import numpy as np\n",
    "import keras\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "import qkeras\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "from qkeras.autoqkeras import AutoQKeras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 19:44:08.171243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.194839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.194979: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.195972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.196058: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.196109: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.909719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.909836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.909898: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 19:44:08.909946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "DEFAULT_INPUT_SIZE = 128\n",
    "\n",
    "train_images_rgx = \"../../dataset/train_set/*/*.jpeg\"\n",
    "test_images_rgx = \"../../dataset/test_set/*/*.jpeg\"\n",
    "\n",
    "train_dataset, test_dataset, num_classes = dataset.create_datasets(\n",
    "    train_images_rgx, test_images_rgx, DEFAULT_BATCH_SIZE, DEFAULT_INPUT_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-02-15 19:44:11.553910: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 33ms/step - loss: 0.2590 - accuracy: 0.9139\n",
      "Accuracy: 0.9139280319213867\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " qtz_inputs (Activation)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " qtz_flatten_input (Activat  (None, 15, 15, 5)         0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EXP_ID = \"baseline_model_v2\"\n",
    "\n",
    "baseline_model = keras.models.load_model(\n",
    "    f\"../handmade/saved_models/{EXP_ID}/best_model_t/model_clean.h5\",\n",
    "    compile=False,\n",
    ")\n",
    "\n",
    "## ADD A LINEAR ACTIVATION LAYER BEFORE FLATTEN\n",
    "x = x_in = keras.Input(shape=(128,128,3))\n",
    "\n",
    "x = keras.layers.Activation(\"linear\", name=\"qtz_inputs\")(x)\n",
    "\n",
    "for l in baseline_model.layers[1:]:\n",
    "    if isinstance(l, keras.layers.Flatten):\n",
    "        x = keras.layers.Activation(\"linear\", name=\"qtz_flatten_input\")(x)\n",
    "    \n",
    "    x = l(x)\n",
    "\n",
    "model = keras.Model(x_in, x)\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.legacy.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(True), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.save(\"tempmodel.h5\")\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"tempmodel.h5\", compile=False)\n",
    "model.compile(\n",
    "    keras.optimizers.legacy.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(True), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "score = model.evaluate(test_dataset)\n",
    "print(\"Accuracy: {}\".format(score[1]))\n",
    "\n",
    "model.summary()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Quantizing a Model With AutoQKeras\n",
    "\n",
    "To quantize this model with AutoQKeras, we need to define the quantization for kernels, biases and activations; forgiving factors and quantization strategy.\n",
    "\n",
    "Below we define which quantizers are allowed for kernel, bias, activations and linear. Linear is a proxy that we use to capture Activation(\"linear\") to apply quantization without applying a non-linear operation. In some networks, we found that this trick may be necessary to better represent the quantization space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantizers we'll test in the bayesian optimization\n",
    "quantization_config = {\n",
    "    \"kernel\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"bias\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"quantized_relu(3,1)\": 3,\n",
    "        \"quantized_relu(4,2)\": 4,\n",
    "        \"quantized_relu(8,2)\": 8,\n",
    "        \"quantized_relu(8,4)\": 8,        \n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "# These are the layer types we will quantize\n",
    "limit = {\n",
    "    \"Dense\": [8, 8, 8],\n",
    "    \"Conv2D\": [8, 8, 8],\n",
    "    \"Activation\": [8],\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model bit size\n",
    "goal_bits = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 5.0,  # We tolerate up to a +5% accuracy change\n",
    "        \"delta_n\": 5.0,  # We tolerate down to a -5% accuracy change\n",
    "        \"rate\": 2.0,  # We want a x2 times smaller model\n",
    "        \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\"default\": [\"parameters\", \"activations\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model energy consumption\n",
    "goal_energy = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 5.0,\n",
    "        \"delta_n\": 5.0,\n",
    "        \"rate\": 1.1,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp32\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_config = {    \n",
    "    \"goal\": goal_bits,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": True,  # Randomely initialize weights\n",
    "    \"mode\": \"bayesian\",  # This can be bayesian,random,hyperband\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    \"tune_filters\": \"none\",\n",
    "    \"tune_filters_exceptions\": \"^dense|^conv2d_2\",\n",
    "    \"distribution_strategy\": None,\n",
    "    \"max_trials\": 200,  # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "from qkeras.autoqkeras import AutoQKeras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoqk = AutoQKeras(\n",
    "    model, output_dir=\"autoqqatwqkeras\", metrics=[\"acc\"], custom_objects={}, **run_config\n",
    ")\n",
    "autoqk.fit(train_dataset, validation_data=test_dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqmodel = autoqk.get_best_model()\n",
    "aqmodel.save_weights(\"autoqqatwqkeras_v2/bestmodel/model_weights.h5\")\n",
    "print_qmodel_summary(aqmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [l for l in aqmodel.layers]\n",
    "x = layers[0].output\n",
    "for i in range(1, len(layers)):\n",
    "    x = layers[i](x)\n",
    "\n",
    "new_model = keras.Model(inputs=[layers[0].input], outputs=[x])\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "new_model.summary()\n",
    "new_model.load_weights(\"autoqqatwqkeras_v2/bestmodel/model_weights.h5\")\n",
    "new_model.save(\"autoqqatwqkeras_v2/bestmodel/model.h5\")\n",
    "print_qmodel_summary(new_model)\n",
    "from qkeras.estimate import print_qstats\n",
    "print_qstats(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = qkeras.utils.load_qmodel(\"autoqqatwqkeras_v2/bestmodel/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2005 - accuracy: 0.9297"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2590 - accuracy: 0.9139\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5603 - accuracy: 0.8044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.560300886631012, 0.8043818473815918]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)\n",
    "new_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 1s 9ms/step - loss: 0.3060 - accuracy: 0.8918 - val_loss: 0.2913 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2547 - accuracy: 0.9085 - val_loss: 0.2924 - val_accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2465 - accuracy: 0.9177 - val_loss: 0.3014 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2590 - accuracy: 0.9120 - val_loss: 0.3178 - val_accuracy: 0.8998\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2629 - accuracy: 0.9075 - val_loss: 0.3251 - val_accuracy: 0.8826\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.9193 - val_loss: 0.3067 - val_accuracy: 0.9030\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2383 - accuracy: 0.9201 - val_loss: 0.2771 - val_accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2337 - accuracy: 0.9245 - val_loss: 0.2882 - val_accuracy: 0.8983\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2368 - accuracy: 0.9236 - val_loss: 0.3219 - val_accuracy: 0.8983\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2288 - accuracy: 0.9302 - val_loss: 0.2874 - val_accuracy: 0.9045\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28735166788101196, 0.9045383334159851]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(train_dataset, batch_size=256, validation_data=test_dataset, epochs=10)\n",
    "new_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_model.save(\"autoqqatwqkeras_v2/bestmodel/new_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 9ms/step\n",
      "accuracy_score 0.9045383411580594\n",
      "precision_score 0.9045575048172492\n",
      "recall_score 0.9035958373200472\n",
      "f1_score 0.9036493303474245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for b in test_dataset.as_numpy_iterator():\n",
    "    x_test.append(b[0])\n",
    "    y_test.append(b[1])\n",
    "\n",
    "x_test = np.concatenate(x_test, 0)\n",
    "y_test = np.concatenate(y_test, 0)\n",
    "\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_qpred = new_model.predict(x_test)\n",
    "y_qpred = np.argmax(y_qpred, axis=1)\n",
    "\n",
    "print(\"accuracy_score\", accuracy_score(y_test, y_qpred))\n",
    "print(\"precision_score\", precision_score(y_test, y_qpred, average=\"macro\"))\n",
    "print(\"recall_score\", recall_score(y_test, y_qpred, average=\"macro\"))\n",
    "print(\"f1_score\", f1_score(y_test, y_qpred, average=\"macro\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
