{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 11:20:27.140031: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-11 11:20:27.163223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-11 11:20:27.163244: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-11 11:20:27.163941: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-11 11:20:27.167924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-11 11:20:27.609664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/\")  # just to enable `dataset`\n",
    "sys.path.append(\"/home/webphy/Desktop/dnn_processor/dataset/\")  # just to enable `dataset`\n",
    "\n",
    "import tensorflow as tf\n",
    "import dataset\n",
    "import numpy as np\n",
    "import keras\n",
    "from datetime import datetime\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 11:20:28.141297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.165820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.165923: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.166934: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.167013: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.167061: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.846243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.846342: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.846398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-11 11:20:28.846447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9352 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "DEFAULT_INPUT_SIZE = 128\n",
    "\n",
    "train_images_rgx = \"../../dataset/train_set_4x/*/*.jpeg\"\n",
    "test_images_rgx = \"../../dataset/test_set_4x/*/*.jpeg\"\n",
    "\n",
    "train_dataset, test_dataset, num_classes = dataset.create_datasets(\n",
    "    train_images_rgx, test_images_rgx, DEFAULT_BATCH_SIZE, DEFAULT_INPUT_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-02-11 11:20:30.377967: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 41ms/step - loss: 0.4989 - accuracy: 0.8582\n",
      "Accuracy: 0.8582375645637512\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " qtz_inputs (Activation)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " qtz_flatten_input (Activat  (None, 15, 15, 5)         0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EXP_ID = \"baseline_model\"\n",
    "\n",
    "baseline_model = keras.models.load_model(\n",
    "    f\"../handmade/saved_models/{EXP_ID}/best_model_t/model.h5\",\n",
    "    compile=False,\n",
    ")\n",
    "\n",
    "## ADD A LINEAR ACTIVATION LAYER BEFORE FLATTEN\n",
    "x = x_in = keras.Input(shape=(128,128,3))\n",
    "\n",
    "x = keras.layers.Activation(\"linear\", name=\"qtz_inputs\")(x)\n",
    "\n",
    "for l in baseline_model.layers[1:]:\n",
    "    if isinstance(l, keras.layers.Flatten):\n",
    "        x = keras.layers.Activation(\"linear\", name=\"qtz_flatten_input\")(x)\n",
    "    \n",
    "    x = l(x)\n",
    "\n",
    "model = keras.Model(x_in, x)\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.legacy.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(True), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.save(\"tempmodel.h5\")\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"tempmodel.h5\", compile=False)\n",
    "model.compile(\n",
    "    keras.optimizers.legacy.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(True), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "score = model.evaluate(test_dataset)\n",
    "print(\"Accuracy: {}\".format(score[1]))\n",
    "\n",
    "model.summary()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Quantizing a Model With AutoQKeras\n",
    "\n",
    "To quantize this model with AutoQKeras, we need to define the quantization for kernels, biases and activations; forgiving factors and quantization strategy.\n",
    "\n",
    "Below we define which quantizers are allowed for kernel, bias, activations and linear. Linear is a proxy that we use to capture Activation(\"linear\") to apply quantization without applying a non-linear operation. In some networks, we found that this trick may be necessary to better represent the quantization space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantizers we'll test in the bayesian optimization\n",
    "quantization_config = {\n",
    "    \"kernel\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"bias\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"quantized_relu(3,1)\": 3,\n",
    "        \"quantized_relu(4,2)\": 4,\n",
    "        \"quantized_relu(8,2)\": 8,\n",
    "        \"quantized_relu(8,4)\": 8,\n",
    "        \"quantized_relu(16,6)\": 16,\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "# These are the layer types we will quantize\n",
    "limit = {\n",
    "    \"Dense\": [8, 8, 8],\n",
    "    \"Conv2D\": [8, 8, 8],\n",
    "    \"Activation\": [8],\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model bit size\n",
    "goal_bits = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 5.0,  # We tolerate up to a +5% accuracy change\n",
    "        \"delta_n\": 5.0,  # We tolerate down to a -5% accuracy change\n",
    "        \"rate\": 2.0,  # We want a x2 times smaller model\n",
    "        \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\"default\": [\"parameters\", \"activations\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model energy consumption\n",
    "goal_energy = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 5.0,\n",
    "        \"delta_n\": 5.0,\n",
    "        \"rate\": 1.1,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp32\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_config = {    \n",
    "    \"goal\": goal_bits,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": True,  # Randomely initialize weights\n",
    "    \"mode\": \"bayesian\",  # This can be bayesian,random,hyperband\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    \"tune_filters\": \"none\",\n",
    "    \"tune_filters_exceptions\": \"^dense|^conv2d_2\",\n",
    "    \"distribution_strategy\": None,\n",
    "    \"max_trials\": 200,  # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "from qkeras.autoqkeras import AutoQKeras\n",
    "import time\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 00m 06s]\n",
      "val_score: 1.5852938890457153\n",
      "\n",
      "Best val_score So Far: 1.872563123703003\n",
      "Total elapsed time: 00h 27m 14s\n"
     ]
    }
   ],
   "source": [
    "autoqk = AutoQKeras(\n",
    "    model, output_dir=\"autoqqatwqkeras\", metrics=[\"acc\"], custom_objects={}, **run_config\n",
    ")\n",
    "autoqk.fit(train_dataset, validation_data=test_dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0010000000474974513\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " qtz_inputs (QActivation)    (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (QConv2D)            (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (QActivation)    (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (QConv2D)          (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (QActivation)  (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (QConv2D)          (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " qtz_flatten_input (QActiva  (None, 15, 15, 5)         0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (QDense)              (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "stats: delta_p=0.05 delta_n=0.05 rate=1.100000023841858 trial_size=36709 reference_size=349292\n",
      "       delta=118.19%\n",
      "Total Cost Reduction:\n",
      "       36709 vs 349292 (-89.49%)\n",
      "qtz_inputs           quantized_bits(4,0,1,alpha=1.0)\n",
      "conv2d               f=4 quantized_bits(4,0,1,alpha=1.0) quantized_bits(4,0,1,alpha=1.0) \n",
      "activation           quantized_relu(3,1)\n",
      "conv2d_1             f=16 quantized_bits(6,0,1,alpha=1.0) quantized_bits(8,0,1,alpha=1.0) \n",
      "activation_1         quantized_relu(3,1)\n",
      "conv2d_2             f=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "qtz_flatten_input    quantized_bits(8,0,1,alpha=1.0)\n",
      "dense                u=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "\n",
      "qtz_inputs           quantized_bits(4,0,1,alpha=1.0)\n",
      "conv2d               f=4 quantized_bits(4,0,1,alpha=1.0) quantized_bits(4,0,1,alpha=1.0) \n",
      "activation           quantized_relu(3,1)\n",
      "conv2d_1             f=16 quantized_bits(6,0,1,alpha=1.0) quantized_bits(8,0,1,alpha=1.0) \n",
      "activation_1         quantized_relu(3,1)\n",
      "conv2d_2             f=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "qtz_flatten_input    quantized_bits(8,0,1,alpha=1.0)\n",
      "dense                u=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqmodel = autoqk.get_best_model()\n",
    "aqmodel.save_weights(\"autoqqatwqkeras/bestmodel/model_weights.h5\")\n",
    "print_qmodel_summary(aqmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " qtz_inputs (QActivation)    (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (QConv2D)            (None, 32, 32, 4)         196       \n",
      "                                                                 \n",
      " activation (QActivation)    (None, 32, 32, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (QConv2D)          (None, 15, 15, 16)        592       \n",
      "                                                                 \n",
      " activation_1 (QActivation)  (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (QConv2D)          (None, 15, 15, 5)         85        \n",
      "                                                                 \n",
      " qtz_flatten_input (QActiva  (None, 15, 15, 5)         0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1125)              0         \n",
      "                                                                 \n",
      " dense (QDense)              (None, 5)                 5630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6503 (25.40 KB)\n",
      "Trainable params: 6503 (25.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "qtz_inputs           quantized_bits(4,0,1,alpha=1.0)\n",
      "conv2d               f=4 quantized_bits(4,0,1,alpha=1.0) quantized_bits(4,0,1,alpha=1.0) \n",
      "activation           quantized_relu(3,1)\n",
      "conv2d_1             f=16 quantized_bits(6,0,1,alpha=1.0) quantized_bits(8,0,1,alpha=1.0) \n",
      "activation_1         quantized_relu(3,1)\n",
      "conv2d_2             f=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "qtz_flatten_input    quantized_bits(8,0,1,alpha=1.0)\n",
      "dense                u=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/webphy/Desktop/dnn_processor_v2/.venv/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "layers = [l for l in aqmodel.layers]\n",
    "x = layers[0].output\n",
    "for i in range(1, len(layers)):\n",
    "    x = layers[i](x)\n",
    "\n",
    "new_model = keras.Model(inputs=[layers[0].input], outputs=[x])\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "new_model.summary()\n",
    "new_model.load_weights(\"autoqqatwqkeras/bestmodel/model_weights.h5\")\n",
    "new_model.save(\"autoqqatwqkeras/bestmodel/model.h5\")\n",
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.8582\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.6820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3268662691116333, 0.6819923520088196]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)\n",
    "new_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 11:48:37.218867: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape/model/activation_1/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-02-11 11:48:37.309912: I external/local_xla/xla/service/service.cc:168] XLA service 0x55c21f33d940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-11 11:48:37.309986: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-02-11 11:48:37.319980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707662917.388216 1223502 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 9ms/step - loss: 0.7650 - accuracy: 0.7896 - val_loss: 0.9767 - val_accuracy: 0.7625\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.8359 - val_loss: 1.0554 - val_accuracy: 0.7739\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4506 - accuracy: 0.8513 - val_loss: 1.0043 - val_accuracy: 0.7548\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.5191 - accuracy: 0.8368 - val_loss: 1.0604 - val_accuracy: 0.7548\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3986 - accuracy: 0.8744 - val_loss: 0.5813 - val_accuracy: 0.8352\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3709 - accuracy: 0.8744 - val_loss: 0.6404 - val_accuracy: 0.8084\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8666 - val_loss: 0.8224 - val_accuracy: 0.8123\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3826 - accuracy: 0.8782 - val_loss: 0.6412 - val_accuracy: 0.8046\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3999 - accuracy: 0.8695 - val_loss: 0.8296 - val_accuracy: 0.7969\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.3591 - accuracy: 0.8767 - val_loss: 0.6470 - val_accuracy: 0.8161\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.8161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6470230221748352, 0.8160919547080994]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(train_dataset, batch_size=256, validation_data=test_dataset, epochs=10)\n",
    "new_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtz_inputs           quantized_bits(4,0,1,alpha=1.0)\n",
      "conv2d               f=4 quantized_bits(4,0,1,alpha=1.0) quantized_bits(4,0,1,alpha=1.0) \n",
      "activation           quantized_relu(3,1)\n",
      "conv2d_1             f=16 quantized_bits(6,0,1,alpha=1.0) quantized_bits(8,0,1,alpha=1.0) \n",
      "activation_1         quantized_relu(3,1)\n",
      "conv2d_2             f=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "qtz_flatten_input    quantized_bits(8,0,1,alpha=1.0)\n",
      "dense                u=5 quantized_bits(4,0,1,alpha=1.0) quantized_bits(2,0,1,alpha=1.0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of operations in model:\n",
      "    conv2d                        : 196608 (smult_4_4)\n",
      "    conv2d_1                      : 129600 (smult_6_3)\n",
      "    conv2d_2                      : 18000 (smult_4_3)\n",
      "    dense                         : 5625  (smult_4_8)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_3                     : 18000\n",
      "    smult_4_4                     : 196608\n",
      "    smult_4_8                     : 5625\n",
      "    smult_6_3                     : 129600\n",
      "\n",
      "Weight profiling:\n",
      "    conv2d_weights                 : 192   (4-bit unit)\n",
      "    conv2d_bias                    : 4     (4-bit unit)\n",
      "    conv2d_1_weights               : 576   (6-bit unit)\n",
      "    conv2d_1_bias                  : 16    (8-bit unit)\n",
      "    conv2d_2_weights               : 80    (4-bit unit)\n",
      "    conv2d_2_bias                  : 5     (2-bit unit)\n",
      "    dense_weights                  : 5625  (4-bit unit)\n",
      "    dense_bias                     : 5     (2-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    conv2d                         : 0.2551\n",
      "    conv2d_1                       : 0.0591\n",
      "    conv2d_2                       : 0.1412\n",
      "    dense                          : 0.3020\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.2763\n"
     ]
    }
   ],
   "source": [
    "from qkeras.estimate import print_qstats\n",
    "\n",
    "print_qstats(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
